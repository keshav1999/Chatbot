{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the lbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time \n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines  = open(\"movie_lines.txt\",encoding='utf-8',errors='ignore').read().split('\\n')\n",
    "conversations =  open(\"movie_conversations.txt\",encoding='utf-8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idline = {}\n",
    "for line in lines:\n",
    "    line_ = line.split(\" +++$+++ \")\n",
    "    if len(line_)==5:\n",
    "        idline[line_[0]]=line_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_id = []\n",
    "for conversation in conversations:\n",
    "    conversation_ = conversation.split(\" +++$+++ \")[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    conversations_id.append(conversation_.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions= []\n",
    "awnsers = []\n",
    "for convers in conversations_id:\n",
    "    for i in range(len(convers)-1):\n",
    "        questions.append(idline[convers[i]])\n",
    "        awnsers.append(idline[convers[i+1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"he's\",\"he is\",text)\n",
    "    text = re.sub(r\"that's\",\"that is\",text)\n",
    "    text = re.sub(r\"she's\",\"she is\",text)\n",
    "    text = re.sub(r\"what's\",\"what is\",text)\n",
    "    text = re.sub(r\"where's\",\"where is\",text)\n",
    "    text = re.sub(r\"\\'ll'\",\" will\",text)\n",
    "    text = re.sub(r\"\\'ve'\",\" have\",text)\n",
    "    text = re.sub(r\"\\'re'\",\" are\",text)\n",
    "    text = re.sub(r\"\\'d'\",\" would\",text)\n",
    "    text = re.sub(r\"didn't\",\"did not\",text)\n",
    "    text = re.sub(r\"we'd\",\"we would\",text)\n",
    "    text = re.sub(r\"it's\",\"it is\",text)\n",
    "    text = re.sub(r\"won't\",\"will not\",text)\n",
    "    text = re.sub(r\"can't\",\"can not\",text)\n",
    "    text = re.sub(r\"[-(){}\\\"#$%^&*!@:;+=.|,]\",\"\",text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_questions = []\n",
    "for quest in questions:\n",
    "    clean_questions.append(clean_text(quest))\n",
    "clean_awnsers= []\n",
    "for ans in awnsers:\n",
    "    clean_awnsers.append(clean_text(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "for word in clean_questions:\n",
    "    for w in  word.split():\n",
    "        if i not in word2count:\n",
    "            word2count[i]=1\n",
    "        else: word2count[i]+=1\n",
    "for word in clean_awnsers:\n",
    "    for w in  word.split():\n",
    "        if i not in word2count:\n",
    "            word2count[i]=1\n",
    "        else: word2count[i]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold =20\n",
    "questionswords2int ={}\n",
    "wordnumber = 0\n",
    "\n",
    "for word,count in word2count.items():\n",
    "    if count>=threshold:\n",
    "        questionswords2int[word] = wordnumber\n",
    "        wordnumber+=1\n",
    "\n",
    "anwserswords2int ={}\n",
    "wordnumber = 0\n",
    "\n",
    "for word,count in word2count.items():\n",
    "    if count >= threshold:\n",
    "        anwserswords2int[word] = wordnumber\n",
    "        wordnumber+=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>','<EOS>','<OUT>','<SOS>']\n",
    "for token in tokens:\n",
    "    questionswords2int[token] = len(questionswords2int) + 1\n",
    "for token in tokens:\n",
    "    anwserswords2int[token] = len(questionswords2int) + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwsersints2words = {w_i: w for w ,w_i in anwserswords2int.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_awnsers)):\n",
    "    clean_awnsers[i] += \"<EOS>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_int = []\n",
    "for question in  clean_questions:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in questionswords2int:\n",
    "            ints.append(questionswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(questionswords2int[word])\n",
    "    questions_to_int.append(ints)\n",
    "\n",
    "anwsers_to_int = []\n",
    "for answsers in  clean_awnsers:\n",
    "    ints = []\n",
    "    for word in answsers.split():\n",
    "        if word not in anwserswords2int:\n",
    "            ints.append(anwserswords2int['<OUT>'])\n",
    "        else:\n",
    "            ints.append(anwserswords2int[word])\n",
    "    anwsers_to_int.append(ints)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clean_question = []\n",
    "sorted_clean_anwsers = []\n",
    "for length in range(1,25+1):\n",
    "    for i in enumerate(questions_to_int):\n",
    "        if len(i[1])==length:\n",
    "            sorted_clean_question.append(questions_to_int[i[0]])\n",
    "            sorted_clean_question.append(anwsers_to_int[i[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building seq-seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input():\n",
    "    inputs = tf.placeholder(tf.int32,[None,None],name='input')\n",
    "    targets = tf.placeholder(tf.int32,[None,None],name='target')\n",
    "    lr = tf.placeholder(tf.float32,name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    \n",
    "    return inputs,targets,lr,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(targets,words2int,batch_size):\n",
    "    left_side = tf.fill([batch_size, 1],word2int['<SOS>'])\n",
    "    right_side = tf.strided_slice(targets,[0,0],[batch_size,-1],[1,1])\n",
    "    preprocessed_targets = tf.concat([left_side,right_side],1)\n",
    "    return preprocessed_targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_rnn_layer(rnn_inputs,rnn_size,num_layers,keep_prob,sequence_length):\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob=keep_prob)\n",
    "    encoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_dropout]*num_layers)\n",
    "    _,encoder_state = tf.nn.bidirectional_dynamic_rnn(cell_fw  = encoder_cell,cell_bw=encoder_cell,sequence_length=sequence_length,inputs=rnn_inputs,dtype=tf.float32)  \n",
    "    return encoder_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
